library(swirl)
swirl()
filter(cran, r_version=="3.1.1", country="US")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(country=="IN", r_version<="3.0.2")
filter(cran, country=="IN", r_version<="3.0.2")
filter(cran, country=="IN" | country =="US")
filter(cran, r_os=="linux-gnu", size > 100500)
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, r_version!=is.na(r_version))
filter(cran, !is.na(r_version))
cran2<-select(cran, size)
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id)
desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), desc(ip_id))
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran, ip_id, package, size)
cran3
cran
mutate(cran3, size_mb=size/ 2^20)
mutate(cran3, size_mb=size/ 2^20, size_gb=size_mb/2^10)
correct_size<-select(cran3, size-1000)
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes=mean(size))
library(dplyr)
mmydf
mydf
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran)
by_package<-group_by(cran, package)
by_package
sumarize(mean(size))
summarize(mean(size))
summarize(_package, mean(size))
summarize(package, mean(size))
summarize(cran, package, mean(size))
summarize( by_package, mean(size))
#
submit()
submit()
?n
submit()
submit()
submit()
reset()
submit()
submit()
submit()
tbl
pack_sum
quantile(pack_sum$count, probs=.99)
top_counts<-filter(pack_sum$count>679)
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,count)
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs=.99)
top_unique<-filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted<-arrange(top_unique, desc(ip_id))
top_unique_sorted<-arrange(top_unique, desc(count))
top_unique_sorted<-arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
?chain
submit()
View(result3)
submit()
reset()
submit()
submit()
submit()
submit()
submit()
library(XML)
url<-"http://release/home/sqatest/yash/lucene-solr/solr/zvrobot/ZVRobot_20150923_123849_181_dir/AzulZVRobotIndex.html"
html<-htmlTreeParse(url, useInternalNodes=T)
title=xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//a[@href]", xmlValue)
filesPath <- "/home/yshthdn/Downloads/getting and cleaning data/"
setwd(filesPath)
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip",method="curl")
###Unzip DataSet to /data directory
unzip(zipfile="./data/Dataset.zip",exdir="./data")
